{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression is a model used in classification problems where the desired prediction is a discrete value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Classification Problems\n",
    "\n",
    "- Identifying email spam\n",
    "- Determining if online ecommerce transactions are fraudulent\n",
    "- Classifying tumors as malignant or benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "- Linear vs Logistic Regression for Classification\n",
    "- Hypothesis Function\n",
    "- Interpretation of Hypothesis Output\n",
    "\n",
    "- Decision Boundary\n",
    "- Cost Function\n",
    "- Simplified Cost Function\n",
    "- Gradient Descent\n",
    "- Advanced Optimization\n",
    "- Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear vs Logistic Regression for Classification\n",
    "\n",
    "Applying Linear Regression to a classification problem is typically not a good idea because of the discrete nature of the y values.\n",
    "\n",
    "- Outliers can heavily skew the model and dramatically hinder the accuracy of the model\n",
    "- Another reason is that in Linear Regression the output of the hypothesis function can be > 1 or < 0 despite the classification values only lying within the range of 0 or 1\n",
    "\n",
    "**Because of these limitations, we ditch the linear model and adopt the logistic model for classifcation problems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Function\n",
    "\n",
    "Since we want our output values to be contained within 0 and 1, we want to use a Sigmoid or Logistic function as the basis for our hypothesis function.\n",
    "\n",
    "In order to step from the Linear model to the Logistic model, we start with our same Linear hypothesis function:\n",
    "\n",
    "$h_{Θ}(x) = Θ^{T}x  $\n",
    "\n",
    "In order to ensure the output values are between 0 and 1, we pass the hypothesis function as a parameter to a Sigmoid/Logistic function $ g(z) $:\n",
    "\n",
    "$g(z) = \\frac{1}{1 + e^{-z}} $\n",
    "\n",
    "Which means the hypothesis function ultimately becomes equivalent to:\n",
    "\n",
    "$h_{Θ}(x) = \\frac{1}{1 + e^{-Θ^{T}x}} $\n",
    "\n",
    "This function is a representation of the Sigmoid/Logistic function which assimptotes at 0 for values approaching -inf and assimptotes at 1 for values approaching inf. All of the function's return values are within the range of 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Hypthothesis Output\n",
    "\n",
    "The hypothesis function output contains a series of probabilities representing the likelihood of y = 1 (i.e. a positive classification).\n",
    "\n",
    "For example, in a problem where we are trying to classify malignant tumors (y=1), then if $h_{Θ}(x) = 0.7 $, we can say there is a 70% chance that the tumor is malignant based on the feature values. Conversely, the probability that the tumor is benign (y=0) would be 30% in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
